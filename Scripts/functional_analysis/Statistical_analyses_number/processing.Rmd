---
title: "SNP.script.1"
author: "Archontis Goumagias"
date: "2022-11-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=10, fig.height=8, out.width='100%', out.height='50%', fig.align='center')
```

```{r}
# Load appropriate libraries
library(data.table)
library(tidyr)
library(dplyr)
library(ggplot2)
library("Biostrings")
library(ape)
library(readr)
library(readxl)
library(RColorBrewer)
library(stringr)
library(viridis)
library(scales)
library(cowplot)
```

```{r}
## Read the data ##

# Get the list of the SNP data
file.list <- list.files(path="./data/E.coli/SNPs/", pattern = fixed(".vcf"))

# Get the list of the annotation data
file.list.ano <- list.files(path="./data/E.coli/annotations", pattern = fixed(".gff"))

# help functions for reading multiple data
read_vcf <- function(data) {
  fread(file=paste("./data/E.coli/SNPs/", data, sep=""), sep='\t', header = TRUE, skip = '#CHROM')
}

read_gff <- function(data) {
  read.gff(file=paste("./data/E.coli/annotations/", data, sep=""))
}

# Then apply the read function to each file
df.list <- lapply(file.list, read_vcf)

# Read the functional annotation data
df.list.ano <- lapply(file.list.ano, read_gff)
```

```{r}

test.1 <- df.list.ano[[1]]

```


```{r}
## Read the data for B. longum ##

# Get the list of the SNP data
file.list <- list.files(path="./data/B.longum/SNPs/", pattern = fixed(".vcf"))

# Get the list of the annotation data
file.list.ano <- list.files(path="./data/B.longum/annotations/", pattern = fixed(".gff"))

# help functions for reading multiple data
read_vcf <- function(data) {
  fread(file=paste("./data/B.longum/SNPs/", data, sep=""), sep='\t', header = TRUE, skip = '#CHROM')
}

read_gff <- function(data) {
  read.gff(file=paste("./data/B.longum/annotations/", data, sep=""))
}

# Then apply the read function to each file
df.list <- lapply(file.list, read_vcf)

# Read the functional annotation data
df.list.ano <- lapply(file.list.ano, read_gff)
```

```{r}
## Read the data for P. dorei ##

# Get the list of the SNP data
file.list <- list.files(path="./data/P.dorei/SNPs/", pattern = fixed(".vcf"))

# Get the list of the annotation data
file.list.ano <- list.files(path="./data/P.dorei/annotations/", pattern = fixed(".gff"))

# help functions for reading multiple data
read_vcf <- function(data) {
  fread(file=paste("./data/P.dorei/SNPs/", data, sep=""), sep='\t', header = TRUE, skip = '#CHROM')
}

read_gff <- function(data) {
  read.gff(file=paste("./data/P.dorei/annotations/", data, sep=""))
}

# Then apply the read function to each file
df.list <- lapply(file.list, read_vcf)

# Read the functional annotation data
df.list.ano <- lapply(file.list.ano, read_gff)
```

```{r}
## Process the data for COG ##

# Some processing on the SNPs

Processing_func_cog <- function(data, annotation,i) {
  colnames(data)[1]<- "CONTIG"
  data <- data %>% select(CONTIG,POS,ID,REF,ALT)
  
  # Filter gene annotations for the SNPs called
  colnames(annotation)[1]<- "CONTIG"
  snp_con_list <- as.vector(data$CONTIG)
  func_snp <- annotation %>% filter(CONTIG %in% snp_con_list) %>% full_join(data, by="CONTIG") %>% mutate(ok = POS >= start & POS <= end) %>% filter(ok==TRUE) %>% mutate(length=end-start+1)
  
  # Keep only the COG attribute
  func_snp$attributes <-  sub(".*cog=", "", func_snp$attributes)
  func_snp$attributes <-  sub(";.*", "", func_snp$attributes)
  
  # Remove SNPs without COG attribute and normalize based on the total gene length 
  cog_terms <- subset(func_snp, startsWith(attributes, "COG")) %>% group_by(attributes) %>% summarize(counts = n(), length.total = sum(unique(length))) %>% mutate(total.number=sum(counts)) %>% mutate(norm.1= counts / total.number) %>% mutate(norm = (norm.1/length.total)*100000) %>% select(attributes, norm)
  
  return(cog_terms)

}
```

```{r}
## Process the data for KEGG ##

# Some processing on the SNPs

Processing_func_kegg <- function(data, annotation,i) {
  colnames(data)[1]<- "CONTIG"
  data <- data %>% select(CONTIG,POS,ID,REF,ALT)
  
  # Filter gene annotations for the SNPs called
  colnames(annotation)[1]<- "CONTIG"
  snp_con_list <- as.vector(data$CONTIG)
  func_snp <- annotation %>% filter(CONTIG %in% snp_con_list) %>% full_join(data, by="CONTIG") %>% mutate(ok = POS >= start & POS <= end) %>% filter(ok==TRUE) %>% mutate(length=end-start+1) 
  
  # Keep only the COG attribute
  func_snp$attributes <-  sub(".*kegg_ko=", "", func_snp$attributes)
  func_snp$attributes <-  sub(";.*", "", func_snp$attributes)

  # Remove SNPs without COG attribute and normalize based on the total gene length 
  kegg_terms <- subset(func_snp, startsWith(attributes, "K")) %>% group_by(attributes) %>% summarize(counts = n(), length.total = sum(unique(length))) %>% mutate(total.number=sum(counts)) %>% mutate(norm.1= counts / total.number) %>% mutate(norm = (norm.1/length.total)*100000) %>% select(attributes, norm)
  
  return(kegg_terms)
}
```

```{r}
# Apply the functions and further process the data (COG) for E. coli

for (i in 1:length(df.list)) {
  var_name <- paste("my_var", i, sep="_")
  assign(var_name,Processing_func_cog(data=df.list[[i]],annotation=df.list.ano[[i]]))
}


# Get the names of the files to be used as labels later
file.list.pro <- sub("_s.*","",file.list)

# Get a list of the created df
name_list <- list(my_var_1,my_var_2,my_var_3,my_var_4,my_var_5,my_var_6,my_var_7,my_var_8,my_var_9,my_var_10,my_var_11,my_var_12,my_var_13,my_var_14,my_var_15,my_var_16,my_var_17,my_var_18,my_var_19,my_var_20,my_var_21,my_var_22,my_var_23,my_var_24,my_var_25,my_var_26,my_var_27,my_var_28,my_var_29,my_var_30,my_var_31,my_var_31,my_var_32,my_var_33,my_var_34,my_var_35,my_var_36,my_var_37,my_var_38,my_var_39,my_var_40,my_var_41,my_var_42,my_var_43,my_var_44,my_var_45,my_var_46,my_var_47,my_var_48,my_var_49,my_var_50,my_var_51,my_var_52,my_var_53,my_var_54,my_var_55,my_var_56,my_var_57,my_var_58,my_var_59,my_var_60,my_var_61,my_var_62,my_var_63,my_var_64,my_var_65,my_var_66,my_var_67,my_var_68,my_var_69,my_var_70,my_var_71,my_var_72,my_var_73,my_var_74,my_var_75,my_var_76,my_var_77)

# Concatenate the datasets 
merged_df <- Reduce(function(x, y) merge(x, y, by = "attributes", all = TRUE), name_list)

# Replace NA values with 0s
merged_df[is.na(merged_df)] <- 0

# Create a list with the COG names
cog.names <- merged_df$attributes

# Remove attributes column
merged_df <- merged_df[,-1]
merged_df <- merged_df[,-78]

# Give row names the names of the corresponding samples
rownames(merged_df) <- cog.names
colnames(merged_df) <- file.list.pro

# Select only samples that surpass the coverage threshold (1M reads)
merged_df <- merged_df %>% select(-ID2_d185, -ID2_d306, -ID2_d310, -ID2_d334, -ID5_d314, -ID7_d218, -ID7_d280, -ID9_d010, -ID10_d052, -ID10_d108, -ID11_d281, -ID12_d060, -ID12_d089, -ID12_d241, -ID12_d315)

# Filter out rows containing more 80 percent 0s
merged_df.new <- merged_df %>% filter(rowMeans(. == 0, na.rm = TRUE) <= 0.8)

# Create a label vector
labels <- as.numeric(gsub(".*_d","",colnames(merged_df.new)))

# plot(labels)

# Save the cleaned data set
write.csv(merged_df.new, "data/E.coli_COG_norm.csv")
# write.csv(labels, "data/E.coli_COG_labels.csv")

```

```{r}
# Apply the functions and further process the data (KEGG) for E. coli

for (i in 1:length(df.list)) {
  var_name <- paste("my_var", i, sep="_")
  assign(var_name,Processing_func_kegg(data=df.list[[i]],annotation=df.list.ano[[i]]))
}

# Get the names of the files to be used as labels later
file.list.pro <- sub("_s.*","",file.list)

# Get a list of the created df
name_list <- list(my_var_1,my_var_2,my_var_3,my_var_4,my_var_5,my_var_6,my_var_7,my_var_8,my_var_9,my_var_10,my_var_11,my_var_12,my_var_13,my_var_14,my_var_15,my_var_16,my_var_17,my_var_18,my_var_19,my_var_20,my_var_21,my_var_22,my_var_23,my_var_24,my_var_25,my_var_26,my_var_27,my_var_28,my_var_29,my_var_30,my_var_31,my_var_31,my_var_32,my_var_33,my_var_34,my_var_35,my_var_36,my_var_37,my_var_38,my_var_39,my_var_40,my_var_41,my_var_42,my_var_43,my_var_44,my_var_45,my_var_46,my_var_47,my_var_48,my_var_49,my_var_50,my_var_51,my_var_52,my_var_53,my_var_54,my_var_55,my_var_56,my_var_57,my_var_58,my_var_59,my_var_60,my_var_61,my_var_62,my_var_63,my_var_64,my_var_65,my_var_66,my_var_67,my_var_68,my_var_69,my_var_70,my_var_71,my_var_72,my_var_73,my_var_74,my_var_75,my_var_76,my_var_77)

# Concatenate the datasets 
merged_df <- Reduce(function(x, y) merge(x, y, by = "attributes", all = TRUE), name_list)

# Replace NA values with 0s
merged_df[is.na(merged_df)] <- 0

# Create a list with the COG names
cog.names <- merged_df$attributes

# Remove attributes column
merged_df <- merged_df[,-1]
merged_df <- merged_df[,-78]

# Give row names the names of the corresponding samples
rownames(merged_df) <- cog.names
colnames(merged_df) <- file.list.pro

# Select only samples that surpass the coverage threshold
merged_df <- merged_df %>% select(-ID2_d185, -ID2_d306, -ID2_d310, -ID2_d334, -ID5_d314, -ID7_d218, -ID7_d280, -ID9_d010, -ID10_d052, -ID10_d108, -ID11_d281, -ID12_d060, -ID12_d089, -ID12_d241, -ID12_d315)

# Convert to matrix
x = as.matrix(merged_df)

# Filter out rows containing more 80 percent 0s
merged_df.new <- merged_df %>% filter(rowMeans(. == 0, na.rm = TRUE) <= 0.8)

# Save the cleaned data set
write.csv(merged_df.new, "data/E.coli_KEGG_norm.csv")

```

```{r}
# Apply the function and further process the data (COG) for B. longum

for (i in 1:length(df.list)) {
  var_name <- paste("my_var", i, sep="_")
  assign(var_name,Processing_func_cog(data=df.list[[i]],annotation=df.list.ano[[i]]))
}

# Get the names of the files to be used as labels later
file.list.pro <- sub("_s.*","",file.list)

# Get a list of the created df
name_list <- list(my_var_1,my_var_2,my_var_3,my_var_4,my_var_5,my_var_6,my_var_7,my_var_8,my_var_9,my_var_10,my_var_11,my_var_12,my_var_13,my_var_14,my_var_15,my_var_16,my_var_17,my_var_18,my_var_19,my_var_20,my_var_21,my_var_22,my_var_23,my_var_24,my_var_25,my_var_26,my_var_27,my_var_28,my_var_29,my_var_30,my_var_31,my_var_31,my_var_32,my_var_33,my_var_34,my_var_35,my_var_36,my_var_37,my_var_38,my_var_39,my_var_40,my_var_41,my_var_42,my_var_43,my_var_44,my_var_45,my_var_46,my_var_47,my_var_48,my_var_49,my_var_50,my_var_51,my_var_52,my_var_53,my_var_54,my_var_55,my_var_56,my_var_57,my_var_58,my_var_59,my_var_60,my_var_61,my_var_62,my_var_63,my_var_64,my_var_65,my_var_66)

# Concatenate the datasets 
merged_df <- Reduce(function(x, y) merge(x, y, by = "attributes", all = TRUE), name_list)

# Replace NA values with 0s
merged_df[is.na(merged_df)] <- 0

# Create a list with the COG names
cog.names <- merged_df$attributes

# Remove attributes column
merged_df <- merged_df[,-1]
merged_df <- merged_df[,-67]

# Give row names the names of the corresponding samples
rownames(merged_df) <- cog.names
colnames(merged_df) <- file.list.pro

# Select only samples that surpass the coverage threshold (1M reads)
merged_df <- merged_df %>% select(-ID2_d306, -ID2_d327, -ID4_d123, -ID8_d310, -ID12_d241)

# Convert to matrix
x = as.matrix(merged_df)

# Filter out rows containing more 80 percent 0s
merged_df.new <- merged_df %>% filter(rowMeans(. == 0, na.rm = TRUE) <= 0.8)

# Save the cleaned data set
write.csv(merged_df.new, "data/B.longum_COG_norm.csv")
```

```{r}
# Apply the function and further process the data (KEGG) for B. longum

for (i in 1:length(df.list)) {
  var_name <- paste("my_var", i, sep="_")
  assign(var_name,Processing_func_kegg(data=df.list[[i]],annotation=df.list.ano[[i]]))
}

# Get the names of the files to be used as labels later
file.list.pro <- sub("_s.*","",file.list)

# Get a list of the created df
name_list <- list(my_var_1,my_var_2,my_var_3,my_var_4,my_var_5,my_var_6,my_var_7,my_var_8,my_var_9,my_var_10,my_var_11,my_var_12,my_var_13,my_var_14,my_var_15,my_var_16,my_var_17,my_var_18,my_var_19,my_var_20,my_var_21,my_var_22,my_var_23,my_var_24,my_var_25,my_var_26,my_var_27,my_var_28,my_var_29,my_var_30,my_var_31,my_var_31,my_var_32,my_var_33,my_var_34,my_var_35,my_var_36,my_var_37,my_var_38,my_var_39,my_var_40,my_var_41,my_var_42,my_var_43,my_var_44,my_var_45,my_var_46,my_var_47,my_var_48,my_var_49,my_var_50,my_var_51,my_var_52,my_var_53,my_var_54,my_var_55,my_var_56,my_var_57,my_var_58,my_var_59,my_var_60,my_var_61,my_var_62,my_var_63,my_var_64,my_var_65,my_var_66)

# Concatenate the datasets 
merged_df <- Reduce(function(x, y) merge(x, y, by = "attributes", all = TRUE), name_list)

# Replace NA values with 0s
merged_df[is.na(merged_df)] <- 0

# Create a list with the COG names
cog.names <- merged_df$attributes

# Remove attributes column
merged_df <- merged_df[,-1]
merged_df <- merged_df[,-67]

# Give row names the names of the corresponding samples
rownames(merged_df) <- cog.names
colnames(merged_df) <- file.list.pro

# Select only samples that surpass the coverage threshold (1M reads)
merged_df <- merged_df %>% select(-ID2_d306, -ID2_d327, -ID4_d123, -ID8_d310, -ID12_d241)

# Convert to matrix
x = as.matrix(merged_df)

# Filter out rows containing more 80 percent 0s
merged_df.new <- merged_df %>% filter(rowMeans(. == 0, na.rm = TRUE) <= 0.8)

# Save the cleaned data set
write.csv(merged_df.new, "data/B.longum_KEGG_norm.csv")

```

```{r}
# Apply the function and further process the data (COG) for P. dorei

for (i in 1:length(df.list)) {
  var_name <- paste("my_var", i, sep="_")
  assign(var_name,Processing_func_cog(data=df.list[[i]],annotation=df.list.ano[[i]]))
}

# Get the names of the files to be used as labels later
file.list.pro <- sub("_s.*","",file.list)

# Get a list of the created df
name_list <- list(my_var_1,my_var_2,my_var_3,my_var_4,my_var_5,my_var_6,my_var_7,my_var_8,my_var_9,my_var_10,my_var_11,my_var_12,my_var_13,my_var_14,my_var_15,my_var_16,my_var_17,my_var_18,my_var_19,my_var_20,my_var_21,my_var_22,my_var_23,my_var_24,my_var_25,my_var_26,my_var_27,my_var_28,my_var_29,my_var_30,my_var_31,my_var_31,my_var_32,my_var_33,my_var_34,my_var_35,my_var_36,my_var_37,my_var_38,my_var_39,my_var_40,my_var_41,my_var_42,my_var_43,my_var_44,my_var_45,my_var_46,my_var_47,my_var_48,my_var_49,my_var_50,my_var_51,my_var_52,my_var_53,my_var_54,my_var_55,my_var_56,my_var_57,my_var_58,my_var_59,my_var_60,my_var_61,my_var_62,my_var_63,my_var_64,my_var_65,my_var_66)

# Concatenate the datasets 
merged_df <- Reduce(function(x, y) merge(x, y, by = "attributes", all = TRUE), name_list)

# Replace NA values with 0s
merged_df[is.na(merged_df)] <- 0

# Create a list with the COG names
cog.names <- merged_df$attributes

# Remove attributes column
merged_df <- merged_df[,-1]
merged_df <- merged_df[,-67]

# Give row names the names of the corresponding samples
rownames(merged_df) <- cog.names
colnames(merged_df) <- file.list.pro

# Rename the duplicate column
colnames(merged_df)[44] <- "ID5_d321_s2"

# Filter out rows containing more 80 percent 0s
merged_df.new <- merged_df %>% filter(rowMeans(. == 0, na.rm = TRUE) <= 0.8)

# Save the cleaned data set
write.csv(merged_df.new, "data/P.dorei_COG_norm.csv")

```

```{r}
# Apply the function and further process the data (KEGG) for P. dorei

for (i in 1:length(df.list)) {
  var_name <- paste("my_var", i, sep="_")
  assign(var_name,Processing_func_kegg(data=df.list[[i]],annotation=df.list.ano[[i]]))
}

# Get the names of the files to be used as labels later
file.list.pro <- sub("_s.*","",file.list)

# Get a list of the created df
name_list <- list(my_var_1,my_var_2,my_var_3,my_var_4,my_var_5,my_var_6,my_var_7,my_var_8,my_var_9,my_var_10,my_var_11,my_var_12,my_var_13,my_var_14,my_var_15,my_var_16,my_var_17,my_var_18,my_var_19,my_var_20,my_var_21,my_var_22,my_var_23,my_var_24,my_var_25,my_var_26,my_var_27,my_var_28,my_var_29,my_var_30,my_var_31,my_var_31,my_var_32,my_var_33,my_var_34,my_var_35,my_var_36,my_var_37,my_var_38,my_var_39,my_var_40,my_var_41,my_var_42,my_var_43,my_var_44,my_var_45,my_var_46,my_var_47,my_var_48,my_var_49,my_var_50,my_var_51,my_var_52,my_var_53,my_var_54,my_var_55,my_var_56,my_var_57,my_var_58,my_var_59,my_var_60,my_var_61,my_var_62,my_var_63,my_var_64,my_var_65,my_var_66)

# Concatenate the datasets 
merged_df <- Reduce(function(x, y) merge(x, y, by = "attributes", all = TRUE), name_list)

# Replace NA values with 0s
merged_df[is.na(merged_df)] <- 0

# Create a list with the COG names
cog.names <- merged_df$attributes

# Remove attributes column
merged_df <- merged_df[,-1]
merged_df <- merged_df[,-67]

# Give row names the names of the corresponding samples
rownames(merged_df) <- cog.names
colnames(merged_df) <- file.list.pro

# Rename the duplicate column
colnames(merged_df)[44] <- "ID5_d321_s2"

# which( duplicated( names( merged_df ) ) )

# Filter out rows containing more 80 percent 0s
merged_df.new <- merged_df %>% filter(rowMeans(. == 0, na.rm = TRUE) <= 0.8)

# Save the cleaned data set
write.csv(merged_df.new, "data/P.dorei_KEGG_norm.csv")

```
